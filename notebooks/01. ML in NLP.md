# 1. 데이터 탐색

## 1. 데이터 시각화

- 차트, 그래프 등 다양한 시각적 도구를 사용하여 데이터를 표현
- 텍스트 데이터의 언어적 패턴과 구조 이해 가능
- 산점도 - 두 변수 간의 관계 표현(패턴/트렌드 식별)
- 히스토그램 - 단일 변수의 분포 표현(이상치/비정상적인 데이터 감지, 편향된 영역 식별)
- PCA, t-SNE 차원 축소 기법 + 네트워크 시각화

## 2. 데이터 정제

- 데이터셋 내의 오류, 불일치, 부정확성 식별 후 수정 및 제거

### 결측치 다루기

- 행 제거하기 - 결측치를 포함하는 행 삭제(결측치 행이 적을 경우)
- 열 제거하기 - 결측치를 포함하는 열 삭제(결측치 열이 적을 경우)
- 평균/중앙값/최빈값 대체 - 결측치를 비결측치에서 계산한 평균/중앙값/최빈값으로 대체
- 회귀 대체 - 데이터셋의 다른 변수들의 값을 기반으로 결측치 예측
- 다중 대체 - 통계 모델을 사용해 여러 개의 대체된 데이터셋 생성 후 결과 종합
- k-최근접 이웃 대체 - 결측치에 가장 가까운 K개의 데이터 포인트 식별 후 이 값을 활용하여 대체

### 중복 제거

- 데이터셋의 모든 행을 비교하여 중복 레코드 식별
- 고유 식별자 열
- 중복 레코드의 첫 번째 발생만 유지하고 이후 발생 모두 제거
- 가장 완전한 정보를 가진 레코드나 가장 최근의 타임스탬프를 가진 레코드 유지

### 데이터 표준화와 변환

- 표준화(Z-점수 정규화) - 각 특성을 평균이 0, 표준 편차가 1이 되도록 변환
    - $x' = \frac{x - \text{mean}(x)}{\text{std}(x)}$
    - 각 특성의 범위가 0을 중심으로 조정 → 큰 값을 가진 특성의 과도한 영향력 방지 가능
- 최소-최대 스케일링 - 데이터를 일관된 값 범위로 재조정(0~1)
    - $x = \frac{x - \min(x)}{\max(x) - \min(x)}$
    - 데이터의 정확한 분포 보다 다른 특성들 간의 의미 있는 비교를 위해 데이터 표준화
- 로그 변환 - 데이터의 이상치와 왜도의 영향 완화

### 이상치 처리

- 이상치 제거 - 이상치로 식별된 관측치 데이터셋에서 제거
- 데이터 변환 - 로그, 제곱근 등의 수학적 함수를 적용하여 데이터 변환
- 윈저화 - 극단값을 데이터셋에서 가장 높은(낮은) 값으로 대체
- 값 대체 - 결측값 또는 극단값을 데이터셋의 나머지 관측치에서 추정된 값으로 대체
- 강건한 통계 기법 사용 - 이상치에 대한 민감도가 낮아 극단값이 존재하더라도 정확한 결과 제공 가능

### 오류 수정

- 수동 검사 - 데이터셋을 수동으로 검사하여 오류 직접 수정
- 통계적 방법 - 데이터가 특정 분포를 따를 때 통계적 기법을 사용하여 이상치 감지 후 제거 및 대체
- 머신러닝 방법 - 머신러닝 알고리즘 적용
- 도메인 지식 - 데이터 내 예상 범위를 고려하여 오류 식별 및 수정
- 값 대체 - 데이터의 결측값 채우기

## 3. 특성 선택

### 필터 방법

- 카이제곱
    - 두 무작위 변수 간의 의존성 측정
    - 실제 관측치와 동일한 정도로 극단적이거나 더 극한적인 결과를 얻을 가능성을 나타내는 P-값 제공
    - 가설 검정 - 수집된 데이터가 예상 데이터와 일치하는지 평가
    - 특성 선택 - 데이터셋의 각 특성과 목표 변수 간의 관계 평가
    - $X^2 = \sum\frac{(O_i - E_i)^2}{E_i}$
- 상호 정보량
    - 두 무작위 변수 간의 상호 의존성을 측정하는 지표
    - 각 특성과 목표 변수 사이의 상호 정보량을 계산하고 최종적으로 가장 높은 상호 정보량 점수를 가진 특성들을 선택
    - $I(X;Y) = \sum_{x \in X}\sum_{y \in Y} P(x, y)\log(\frac{P(x, y)}{P(x)P(y)})$
- 상관 계수
    - 두 변수 간의 선형 관계의 강도와 방향을 나타내는 지표
    - 피어슨 상관 계수 - 두 연속형 변수 간의 선형 관계 측정(-1~1)
        
        $r = \frac{\text{cov}(X, Y)}{\text{std}(X)\cdot\text{std}(Y)}$
        
    - 비선형/범주형 → 스피어먼 순위 상관 계수/켄달 상관 계수

### 래퍼 방법

- 반복적인 모델 훈련과 테스트를 통해 특성 부분 집합을 탐색하는 기술
- 재귀적 특성 제거
    - 사전 설정된 특성 수가 남을 때까지 중요도가 낮은 특성을 하나씩 제거
    - 후진 제거 접근법으로 작동
- 전진 선택/후진 제거

### 임베디드 방법

- 모델 훈련 과정 중에 특성을 선택하는 기법
- 라쏘 회귀
    - 최소 절대 수축 및 선택 연산자의 약자
    - 표준 회귀 손실 함수에 패널티 항을 도입하는 방법
    - 특성의 수가 샘플 수를 크게 상회하는 고차원 데이터에 유용
    - $\min_w ||y - Xw||_2^2 + \lambda ||w||_1$
- 릿지 회귀
    - 특성 선택에 적용 가능한 선형 회귀 방법
    - 일반적인 최소 제곱 회귀와 유사하지만 비용 함수에 패널티 항 추가
    - 계수 크기의 제곱에 비례하는 패널티 항을 포함하여 비용 함수 수정
    - $\min_w ||y - Xw||_2^2 + \alpha ||w||_2^2$
- 데이터셋에 많은 특성이 있고 그중 일부만 중요할 것으로 예상되는 경우 → 라쏘 회귀
- 대부분의 특성이 어느 정도 관련성이 있을 것으로 예상되는 경우 → 릿지 회귀

### 차원 축소

- 가능한 한 많은 정보를 유지하면서 특성을 저차원 공간으로 변환하는 방법
- PCA
    - 상관된 변수 집합을 주성분이라는 상관되지 않은 변수 집합으로 변환
    - 데이터에서 최대 분산의 방향을 식별하고 데이터를 이러한 방향으로 투영하여 데이터의 차원을 축소
    - 데이터 표준화 - 각 특성은 평균이 0, 분산이 1
    - 공분산 행렬 계산 - 데이터의 특성 쌍 간의 선형 관계를 측정하는 정방행렬
    - 공분산 행렬의 고유벡터와 고윳값 계산 - 고유벡터는 데이터셋 내에서 가장 높은 분산의 주요 방향을 나타내고 고윳값은 각 고유벡터가 설명하는 분산의 크기를 나타냄
    - 주성분의 수 선택 - 고윳값을 분석하여 가장 많은 분산을 설명하는 상위 k개의 고유벡터를 선택하여 유지할 주성분의 수 결정
    - 선택된 주성분으로 데이터 투영 - 원래 데이터를 선택된 주성분에 투영하여 저차원으로 표현
- LDA
    - 원래의 특성을 낮은 차원의 공간으로 변환하여 클래스 간 차별적 정보를 최대한 유지하면서 특성 수 감소
    - 원래의 특성들의 선형 결합을 찾아 클래스 간의 분리 극대화
    - 각 클래스의 평균 벡터 계산
    - 각 클래스의 공분산 행렬 계산
    - 전체 평균 벡터와 전체 공분산 행렬 계산
    - 클래스 간 산포 행렬 계산
    - 클래스 내 산포 행렬 계산
    - $S_w^{-1}S_b$로 행렬의 고유벡터와 고윳값 계산
    - 가장 높은 고윳값을 갖는 상위 k개 고유벡터를 새로운 특성 공간으로 선택
- t-SNE
    - 데이터 포인트 간의 거리를 보존하는 대신, 저차원 공간에서 데이터 포인트 쌍 간의 유사성 보존
    - 고차원 공간에서 각 데이터 포인트 쌍 간의 유사성 계산
    - 유사성 행렬을 소프트맥스 함수를 사용하여 확률 분포 변환
    - 저차원 공간에서 각 데이터 포인트 쌍 간의 유사성 계산
    - 고차원 공간의 쌍별 유사성과 저차원 공간의 쌍별 유사성 간의 차이 최소화를 위해 저차원 공간에서 점들의 위치 조정