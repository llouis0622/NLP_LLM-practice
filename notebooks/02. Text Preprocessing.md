# 1. 자연어 처리에서 소문자 변환

- 모든 텍스트를 소문자로 변환
- 텍스트를 일관되게 만들어 대소문자 차이로 인한 불일치 방지
- 텍스트 분류, 감정 분석, 언어 모델링에 유용

# 2. 특수 문자와 구두점 제거

## 1. 불용어 제거

- 불용어 : 문장이나 텍스트의 의미에 큰 기여를 하지 않는 단어
- 감정 분석, 주제 모델링, 정보 검색 등의 텍스트 분석 작업 수행 전 전처리 과정
- 어휘 크기와 특성 공간의 차원을 줄여 이후 분석 단계의 효율성과 효율 증가
- 미리 정의된 목록이나 코퍼스에서 학습된 불용어 목록 식별 → 입력 텍스트를 단어 또는 토큰으로 토큰화 → 불용어 목록과 일치하는 단어 제거

### 맞춤법 검사와 교정

- 텍스트 내의 철자 오류를 수정하는 작업

### 표제어 추출

- 단어를 기본 형태 또는 사전 형태인 표제어로 단순화하는 텍스트 정규화 기법
- 동일한 단어의 다양한 형태를 하나의 통합된 용어로 분석할 수 있도록 함

### 어간 추출

- 단어를 기본적이거나 뿌리 형태로 축소하는 과정
- 단어의 끝부분이나 접미사를 잘라내 어간만 남기는 방식
- 한 단어의 모든 굴절형이나 파생형을 공통의 기본 형태로 변환하는 것
- 포터 어간 추출 알고리즘 : 일련의 규칙에 따라 접미사를 식별하고 이를 제거하여 어간 추출

# 3. 개체명 인식

- 텍스트 내에서 사람 이름, 조직 이름, 위치 등을 포함한 명명된 개체를 탐지하고 분류하는 것
- 비정형 텍스트 데이터에서 이러한 명명된 개체를 자동으로 식별하고 정보를 추출하는 것
- 조건부 무작위장, 순환 신경망 사용

### 명명된 개체 범주

- 인물 : 명명된 개인
- 조직 : 명명된 회사, 기관, 조직
- 위치 : 명명된 장소
- 날짜 : 날짜, 시간
- 제품 : 명명된 제품, 브랜드

### 개체명 인식 수행 방법

- 데이터 수집 : 개체명 인식에 사용될 데이터 수집
- 전처리 : 토큰화, 불용어 제거, 어간 추출, 표제어 추출, 정규화 등의 전처리
- 레이블링 : 데이터에 개체명 태그 레이블링
    - IOB 태깅 체계 : B(개체명의 시작), I(개체명의 내부), O(개체명의 외부)로 레이블링
- 훈련 : 미등록어에서 개체명을 인식하도록 기계 학습 모델 훈련
    - 규칙 기반 시스템, 통계적 모델, 딥러닝 모델 등 사용
- 평가 : 테스트 데이터셋에서 모델의 성능 평가
- 배포 : 훈련된 모델을 미등록어에 대해 개체명 인식을 수행하도록 배포

### 라이브러리

- spaCy : 다양한 자연어 처리 작업을 위해 설계된 오픈 소스 라이브러리, 사전 학습 모델 제공
- NLTK : 다양한 자연어 처리 작업을 위해 사용되는 라이브러리, 사전 학습 모델 제공
- Stanford Named Entity Recognizer : 자바 기반 개체명 인식 도구
- AllenNLP : 자연어 처리 모델 구축 및 평가용 오픈 소스 라이브러리
- Flair : 최첨단 자연어 처리를 위한 라이브러리
- General Architecture for Text Engineering : 자여너 처리를 위한 도구 모음

# 4. 품사 태깅

- 문장에서 각 단어에 명사, 동사, 형용사 등과 같은 문법적 역할을 지정하는 과정

## 1. 규칙 기반 방법

- 텍스트 내의 단어들을 명사, 동사, 형용사 등으로 자동 태깅하기 위해 일련의 규칙이나 패턴을 정의하는 접근 방식
- 정규 표현식과 패턴 매칭 소프트웨어 자동화 → 각 단어 품사 식별

### 규칙 기반 방법 장점

- 규칙이 잘 설계되고 다양한 언어적 현상을 포괄할 때 높은 정확도 제공 가능
- 특정 도메인이나 장르에 맞게 규칙 맞춤화 가능

### 규칙 기반 방법 단점

- 자연어의 복잡성과 변화를 완전히 포착하지 못할 수 있음
- 언어가 시간에 따라 진화하고 변화함에 따라 규칙을 개발하고 유지하는 데 상당한 노력 필요
- 문맥에 따라 여러 가지 품사로 사용될 수 있는 단어의 모호성 처리 어려움

## 2. 통계적 방법

- 확률적 모델을 사용하여 문장 내 각 단어에 가장 적절한 품사 태그를 자동으로 할당
- 이미 품사 태그가 부여된 텍스트 말뭉치를 학습 데이터로 사용하여 특정 단어가 각 태그와 연관된 확률 학습

### 은닉 마르코프 모델

- 텍스트를 포함한 순차적 데이터를 다루는 데 널리 사용되는 확률적 모델
- 단어 시퀀스에 대한 품사 태그 시퀀스의 확률 분포 모델링
- 문장 내 특정 위치의 품사 태그가 바로 앞 태그에만 의존한다고 가정
- 주어진 태그에 대한 특정 단어의 확률이 문장 내 다른 단어들과 독립적이라 가정
- 주어진 문장에 대해 가장 가능성 높은 품사 태그 시퀀스를 찾기 위해 비터비 알고리즘 사용

### 조건부 랜덤 필드

- 품사 태깅을 포함한 시퀀스 레이블링 작업에 자주 사용되는 또 다른 확률적 모델
- 입력 시퀀스와 출력 시퀀스의 결합 확률이 아닌 입력 시퀀스가 주어졌을 때 출력 시퀀스의 조건부 확률 모델링
- 입력과 출력 시퀀스 간의 더 복잡한 관계 포착 가능
- 경사 하강법이나 L-BFGS 같은 반복적 알고리즘을 사용해 모델의 최적 가중치 학습

### 통계적 방법 장점

- 단어의 문맥과 문장 내 단어들 간의 관계를 포착하여 더 정확한 태깅 결과 제공
- 학습 데이터에 없는 새로운 단어와 문장도 처리 가능
- 대규모 데이터셋으로 학습이 가능하여 언어의 다양한 변형과 패턴 포착 가능

### 통계적 방법 단점

- 학습을 위해 대량의 주석이 달린 데이터 필요, 준비하는 데 시간과 비용 많이 소요
- 학습 데이터의 품질에 민감, 데이터에 노이즈가 많거나 편향되어 있을 시 성능 저하 발생
- 대부분의 통계적 모델은 블랙박스 특성으로 모델의 의사결정 과정 해석 어려움

## 3. 딥러닝 기반 접근법

- 주어진 문장에서 각 단어의 품사 태그를 예측하기 위해 신경망 모델을 훈련하는 것
- 텍스트 데이터에서 복잡한 패턴과 관계를 학습하여 단어를 적절한 품사로 정확하게 태깅 가능

### LSTM RNN

- 단어의 시쿠너스를 처리하고 그들 사이의 의존성 포착 가능
- 고차원 공간에서 단어의 벡터 표현인 워드 임베딩 시퀀스
- 입력 레이어 : 워드 임베딩을 입력으로 받아들임
- 장단기 메모리 레이어 : 임베딩의 시퀀스를 처리하여 그들 사이의 상호 의존성을 이해하려고 시도
- 출력 레이어 : 입력 시퀀스 내 각 단어에 대해 품사 태그를 예측하는 역할

### BERT 트랜스포머 기반 모델

- 문장 내 단어들 간의 문맥적 관계를 깊이 있게 이해할 수 있도록 트랜스포머 기반 아키텍처 사용
- 방대한 텍스트 데이터로 학습, 품사 태깅을 포함한 다양한 자연어 처리 작업에서 뛰어난 성능 발휘를 위한 미세 조정 가능
- 입력 문장을 토큰화하고 각 토큰에 초기 품사 태그를 할당해야 함
- 토큰 임베딩을 사전 훈련된 BERT 모델에 입력 시 각 토큰에 대한 문맥화된 임베딩 출력
- 순방향 신경망을 통해 처리되어 각 토큰의 최종 품사 태그 예측 가능

## 4. 정규 표현식

- 현대 프로그래밍 언어와 소프트웨어에서 다양한 용도로 사용되는 텍스트 패턴의 한 유형
- 입력이 특정 텍스트 페턴을 따르는지 검증
- 더 큰 텍스트 본문에서 해당 패턴과 일치하는 텍스트 찾기
- 일치하는 텍스트를 다른 텍스트로 대체
- 일치한 텍스트의 일부 재배열
- 텍스트 블록을 여러 하위 텍스트로 분리
- 문자와 메타문자의 조합 → 텍스트 문자열 내에서 검색할 패턴 형성

### 유효성 검증

- 입력이 특정 패턴과 일치하는지 검증 가능

### 텍스트 조작

- 패턴 매칭 기법을 사용하여 문서나 데이터셋에서 텍스트 문자열을 찾고 조작하는 작업
- 검색 및 교체 : 문서 내 특정 패턴이나 문자 시퀀스 검색, 이를 다른 텍스트나 형식으로 교체
- 데이터 추출 : 특정 데이터 형식과 일치하는 패턴을 정의하여 텍스트에서 데이터를 추출하는 작업
- 정규 표현식 패턴 정의 : 추출하려는 데이터와 일치하는 정규 표현식 패턴 정의
- 정규 표현식 패턴 컴파일 : 정규 표현식 패턴 정의 후 정규 표현식 객체로 컴파일
- 텍스트에서 패턴 검색 : 정규 표현식 객체를 컴파일한 후 이를 사용해 텍스트에서 해당 패턴 검색
- 일치하는 데이터 추출 : 텍스트에서 패턴을 검색한 후 해당 페턴과 일치하는 데이터 추출

### 텍스트 정제

- 정규 표현식을 사용하여 텍스트 데이터를 정리하고 표준화하는 과정
- 불필요한 문자, 공백, 기타 형식을 제거하는 것
- 특수 문자 제거 : 구두점, 괄호, 기타 특수 기호 같은 특정 문자를 찾아 제거
- 불용어 제거 : 의미 있는 단어에 집중하기 위해 텍스트에서 제거
- HTML 태그 제거 : 웹사이트에서 스크랩한 텍스트를 분석하기 전에 제거
- 텍스트 소문자 변환 : 모든 텍스트를 소문자 또는 대문자로 변환
- 텍스트 정규화 : 텍스트를 표준 형식으로 변환하는 과정

### 구문 분석

- 특정 문법에 따라 텍스트 문자열의 문법적 구조를 분석하는 과정
- 분석하고자 하는 언어의 문법 정의
- 정규 표현식을 활용해 문장의 각 구성 요소와 그들 간의 관계 식별
- 문법 내에서 다양한 품사와 문장 구조에 해당하는 패턴 정의
- 문장의 문법 구조를 나타내는 구문 트리 또는 기타 데이터 구조 활용

## 5. 토큰화

- 자연어 처리에서 텍스트나 문장을 개별 단어 또는 용어로 나누는 과정
- 비구조화된 텍스트 데이터를 구조화된 형식으로 변환하는 것

### 단어 토큰화

- 공백, 구두점, 기타 문자를 구분자로 사용해 텍스트를 개별 단어 또는 토큰으로 분리

### 문장 토큰화

- 마침표, 느낌표, 물음표 같은 구두점을 구분자로 사용해 텍스트를 개별 문장으로 분리

### 정규 표현식 토큰화

- 정규 표현식을 사용해 토큰화 규칙을 정의하는 것

# 5. 전처리 파이프라인 설명

- 디코딩/인코딩 제거
- 소문자화
- 숫자를 단어로 변환
- 구두점 및 기타 특수 문자 제거
- 맞춤법 교정
- 불용어 제거
- 어간 추출
- 표제어 추출