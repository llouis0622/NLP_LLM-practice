{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-07T11:49:01.073621Z",
     "start_time": "2026-01-07T11:48:57.541443Z"
    }
   },
   "source": [
    "from num2words.lang_PL import suffixes\n",
    "\n",
    "default_installations = True\n",
    "if default_installations:\n",
    "    !pip install -q num2words autocorrect\n",
    "else:\n",
    "    import requests\n",
    "\n",
    "    text_file_path = \"requirements__Ch4_Preprocessing_Pipeline.txt\"\n",
    "    url = \"https://raw.githubusercontent.com/PacktPublishing/Mastering-NLP-from-Foundations-to-LLMs/main/Chapter4_notebooks/\" + text_file_path\n",
    "    res = requests.get(url)\n",
    "    with open(text_file_path, \"w\") as f:\n",
    "        f.write(res.text)\n",
    "\n",
    "    !pip install -r requirements__Ch4_Preprocessing_Pipeline.txt"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T11:50:58.288608Z",
     "start_time": "2026-01-07T11:50:58.077990Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "from num2words import num2words\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from autocorrect import Speller\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ],
   "id": "be18f3e8acf83a12",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/llouis/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/llouis/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to /Users/llouis/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T12:03:21.077911Z",
     "start_time": "2026-01-07T12:03:21.074589Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def decode(text):\n",
    "    text = re.sub(\"\\\\n|\\\\r|\\\\t|-\", \" \", text)\n",
    "    subject_line_search = re.search(r\"<SUBJECT LINE>(.*?)<END>\", text, flags=re.S)\n",
    "    body_text_search = re.search(r\"<BODY TEXT>(.*?)<END>\", text, flags=re.S)\n",
    "\n",
    "    formated_output  = \"\"\n",
    "    if subject_line_search:\n",
    "        formated_output = formated_output + subject_line_search.groups()[0] + \". \"\n",
    "    if body_text_search:\n",
    "        formated_output = formated_output + body_text_search.groups()[0] + \".\"\n",
    "    return formated_output\n",
    "\n",
    "\n",
    "def digits_to_words(match):\n",
    "    suffixes = ['st', 'nd', 'rd', 'th']\n",
    "    string = match[0].lower()\n",
    "    if string[-2:] in suffixes:\n",
    "        type = 'ordinal'\n",
    "        string = string[:-2]\n",
    "    else:\n",
    "        type = 'cardinal'\n",
    "    return num2words(string, to=type)\n",
    "\n",
    "\n",
    "def spelling_correction(text):\n",
    "    corrector = Speller()\n",
    "    spells = [corrector(word) for word in text.split()]\n",
    "    return \" \".join(spells)\n",
    "\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    stopwords_set = set(stopwords.words('english'))\n",
    "    return \" \".join([word for word in text.split() if word not in stopwords_set])\n",
    "\n",
    "\n",
    "def stemming(text):\n",
    "    stemmer = PorterStemmer()\n",
    "    return \" \".join([stemmer.stem(word) for word in text.split()])\n",
    "\n",
    "\n",
    "def lemmatizing(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return \" \".join([lemmatizer.lemmatize(word) for word in text.split()])"
   ],
   "id": "19d1f26d70a7e771",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T12:04:00.835464Z",
     "start_time": "2026-01-07T12:04:00.830563Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocessing(input_text, printing=False):\n",
    "    output = input_text\n",
    "\n",
    "    output = decode(output)\n",
    "    print(\"\\n디코딩/인코딩 제거:\\n        \", output)\n",
    "\n",
    "    output = output.lower()\n",
    "    print(\"\\n소문자로 변환:\\n        \", output)\n",
    "\n",
    "    output = re.sub(r'\\d+(st)?(nd)?(rd)?(th)?', digits_to_words, output, flags=re.IGNORECASE)\n",
    "    print(\"\\n숫자를 단어로 변환:\\n        \", output)\n",
    "\n",
    "    output = re.sub('[^A-Za-z0-9]+', ' ', output)\n",
    "    print(\"\\n구두점 및 기타 특수 문자 제거:\\n        \", output)\n",
    "\n",
    "    output = spelling_correction(output)\n",
    "    print(\"\\n철자 교정:\\n        \", output)\n",
    "\n",
    "    output = remove_stop_words(output)\n",
    "    print(\"\\n불용어 제거:\\n        \", output)\n",
    "\n",
    "    output = stemming(output)\n",
    "    print(\"\\n어간 추출:\\n        \", output)\n",
    "\n",
    "    output = lemmatizing(output)\n",
    "    print(\"\\n표제어 추출:\\n        \", output)\n",
    "\n",
    "    return output"
   ],
   "id": "106d0f0add89071f",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T12:04:01.433747Z",
     "start_time": "2026-01-07T12:04:01.389012Z"
    }
   },
   "cell_type": "code",
   "source": [
    "raw_text_input = \"\"\"\n",
    "\"<SUBJECT LINE> Employees details<END><BODY TEXT>Attached are 2 files,\\n1st one is pairoll, 2nd is healtcare!<END>\"\n",
    "\"\"\"\n",
    "print(f\"This is the input raw text:\\n{raw_text_input}\")\n",
    "print(f\"\\n----------------------------\\nThis is the preprocessed text:\\n        {preprocessing(raw_text_input, printing=True)}\")"
   ],
   "id": "7ce2d2823a114fcc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the input raw text:\n",
      "\n",
      "\"<SUBJECT LINE> Employees details<END><BODY TEXT>Attached are 2 files,\n",
      "1st one is pairoll, 2nd is healtcare!<END>\"\n",
      "\n",
      "\n",
      "디코딩/인코딩 제거:\n",
      "          Employees details. Attached are 2 files, 1st one is pairoll, 2nd is healtcare!.\n",
      "\n",
      "소문자로 변환:\n",
      "          employees details. attached are 2 files, 1st one is pairoll, 2nd is healtcare!.\n",
      "\n",
      "숫자를 단어로 변환:\n",
      "          employees details. attached are two files, first one is pairoll, second is healtcare!.\n",
      "\n",
      "구두점 및 기타 특수 문자 제거:\n",
      "          employees details attached are two files first one is pairoll second is healtcare \n",
      "\n",
      "철자 교정:\n",
      "         employees details attached are two files first one is payroll second is healthcare\n",
      "\n",
      "불용어 제거:\n",
      "         employees details attached two files first one payroll second healthcare\n",
      "\n",
      "어간 추출:\n",
      "         employe detail attach two file first one payrol second healthcar\n",
      "\n",
      "표제어 추출:\n",
      "         employe detail attach two file first one payrol second healthcar\n",
      "\n",
      "----------------------------\n",
      "This is the preprocessed text:\n",
      "        employe detail attach two file first one payrol second healthcar\n"
     ]
    }
   ],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
