{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-10T12:22:05.352152Z",
     "start_time": "2026-01-10T12:22:04.092785Z"
    }
   },
   "source": [
    "default_installations = True\n",
    "if default_installations:\n",
    "    !pip -q install --upgrade openai\n",
    "else:\n",
    "    import requests\n",
    "\n",
    "    text_file_path = \"requirements__Ch8_Setting_Up_Close_Source_and_Open_Source_LLMs.txt\"\n",
    "    url = \"https://raw.githubusercontent.com/PacktPublishing/Mastering-NLP-from-Foundations-to-LLMs/main/Chapter8_notebooks/\" + text_file_path\n",
    "    res = requests.get(url)\n",
    "    with open(text_file_path, \"w\") as f:\n",
    "        f.write(res.text)\n",
    "    !pip install -r requirements__Ch8_Setting_Up_Close_Source_and_Open_Source_LLMs.txt"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T12:22:07.710956Z",
     "start_time": "2026-01-10T12:22:07.471597Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import openai\n",
    "import re\n",
    "import time"
   ],
   "id": "2455e06d759365b4",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T12:22:11.248607Z",
     "start_time": "2026-01-10T12:22:11.246431Z"
    }
   },
   "cell_type": "code",
   "source": "api_key = \"...\"",
   "id": "1b6b7a168acad042",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T12:22:15.352147Z",
     "start_time": "2026-01-10T12:22:15.301413Z"
    }
   },
   "cell_type": "code",
   "source": [
    "client = openai.OpenAI(api_key=api_key)\n",
    "client"
   ],
   "id": "2d3f80d7db267e15",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<openai.OpenAI at 0x105262c90>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T12:22:18.095845Z",
     "start_time": "2026-01-10T12:22:16.067527Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\",\n",
    "         \"content\": \"당신은 도움이 되는 어시스턴트입니다. 간단한 답변을 제공하며, 답변은 Markdown 문법으로 포맷합니다.\"},\n",
    "        {\"role\": \"user\",\n",
    "         \"content\": \"Python 라이브러리 pandas를 어떻게 임포트하나요?\"},\n",
    "        {\"role\": \"assistant\",\n",
    "         \"content\": \"다음과 같이 pandas를 임포트할 수 있습니다:  \\n```\\nimport pandas as pd\\n```\"},\n",
    "        {\"role\": \"user\",\n",
    "         \"content\": \"Python 라이브러리 numpy를 어떻게 임포트하나요?\"}\n",
    "    ])\n",
    "text = response.choices[0].message.content.strip()\n",
    "print(text)"
   ],
   "id": "2499af2f6142a3e9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "다음과 같이 numpy를 임포트할 수 있습니다:  \n",
      "```python\n",
      "import numpy as np\n",
      "```\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T12:22:20.707538Z",
     "start_time": "2026-01-10T12:22:20.702698Z"
    }
   },
   "cell_type": "code",
   "source": "response.choices[0].message.content.strip()",
   "id": "efef5ee4a97c4581",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'다음과 같이 numpy를 임포트할 수 있습니다:  \\n```python\\nimport numpy as np\\n```'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T12:22:21.235702Z",
     "start_time": "2026-01-10T12:22:21.233325Z"
    }
   },
   "cell_type": "code",
   "source": [
    "openai_model = \"gpt-4o-mini\"\n",
    "temperature = 0\n",
    "max_attempts = 5\n",
    "attempts = 0"
   ],
   "id": "b64a96da5f44ab2",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T12:22:21.775672Z",
     "start_time": "2026-01-10T12:22:21.773491Z"
    }
   },
   "cell_type": "code",
   "source": [
    "system_prompt = \"당신은 통찰력 있는 어시스턴트입니다. 질문을 받으면 답변을 명확하게 설명합니다. 답변을 마친 후에는 프롬프트의 모든 단어를 주의 깊게 검토하여 오타를 찾아내고, 마지막으로 해당 오타들에 대한 수정 사항을 제시합니다.\"\n",
    "user_prompt_oai = \"신경과학이 사람이 죽기 전 마지막 생각을 주출할 수 있다면, 세상은 어떻게 달아질까요?\""
   ],
   "id": "a5ca4073f8aa58ca",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T12:22:22.293078Z",
     "start_time": "2026-01-10T12:22:22.290927Z"
    }
   },
   "cell_type": "code",
   "source": [
    "messages = []\n",
    "messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
    "messages.append({\"role\": \"user\", \"content\": user_prompt_oai})"
   ],
   "id": "9aaf79598f48ffe4",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T12:22:31.396910Z",
     "start_time": "2026-01-10T12:22:22.908516Z"
    }
   },
   "cell_type": "code",
   "source": [
    "while True:\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=openai_model,\n",
    "            messages=messages,\n",
    "            temperature=temperature)\n",
    "        response_oai = response.choices[0].message.content.strip()\n",
    "        response_oai = re.sub(r'\\. ', r'. \\n', response_oai)\n",
    "        print(f\"프롬프트: {user_prompt_oai}\\n\\n{openai_model}'의 응답: \\n{response_oai}\")\n",
    "        break\n",
    "    except Exception as output:\n",
    "        attempts += 1\n",
    "        if attempts >= max_attempts:\n",
    "            print(f\"Quitting due to {openai_model} error: {output}\")\n",
    "            break\n",
    "        print(f\"Attempt #{attempts} failed: {output}\")\n",
    "        time.sleep(1)"
   ],
   "id": "9e679067305c7aee",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "프롬프트: 신경과학이 사람이 죽기 전 마지막 생각을 주출할 수 있다면, 세상은 어떻게 달아질까요?\n",
      "\n",
      "gpt-4o-mini'의 응답: \n",
      "신경과학이 사람이 죽기 전 마지막 생각을 추출할 수 있다면, 세상은 여러 면에서 크게 변화할 수 있습니다. \n",
      "\n",
      "\n",
      "1. \n",
      "**죽음에 대한 이해**: 사람들이 죽기 전의 마지막 생각을 알 수 있다면, 죽음에 대한 두려움이나 불확실성이 줄어들 수 있습니다. \n",
      "이는 죽음을 보다 자연스럽고 수용할 수 있는 과정으로 만들 수 있습니다.\n",
      "\n",
      "2. \n",
      "**의료 윤리**: 마지막 생각을 추출하는 기술이 발전하면, 환자의 의사결정 능력이나 고통을 줄이는 방법에 대한 논의가 활발해질 것입니다. \n",
      "예를 들어, 환자가 원하는 치료 방법이나 연명의료 중단에 대한 의사를 명확히 할 수 있는 기회가 생길 수 있습니다.\n",
      "\n",
      "3. \n",
      "**심리적 영향**: 마지막 생각이 긍정적이거나 부정적일 경우, 이를 통해 남은 가족이나 친구들이 그 사람의 삶을 어떻게 기억하고 기념할지를 결정하는 데 영향을 미칠 수 있습니다.\n",
      "\n",
      "4. \n",
      "**철학적 질문**: 마지막 생각을 추출하는 것이 가능해지면, 인간의 의식, 자아, 그리고 죽음의 의미에 대한 철학적 논의가 더욱 깊어질 것입니다. \n",
      "이는 인간 존재에 대한 새로운 관점을 제시할 수 있습니다.\n",
      "\n",
      "5. \n",
      "**사회적 변화**: 사람들이 죽음을 맞이하는 방식이 변화하면서, 장례 문화나 죽음에 대한 사회적 태도도 변화할 수 있습니다. \n",
      "예를 들어, 마지막 생각을 공유하는 것이 일반화된다면, 죽음에 대한 대화가 더 개방적이고 솔직해질 수 있습니다.\n",
      "\n",
      "이러한 변화들은 긍정적일 수도, 부정적일 수도 있으며, 사회 전반에 걸쳐 다양한 논의와 갈등을 일으킬 수 있습니다.\n",
      "\n",
      "**오타 수정 사항**:\n",
      "- \"주출\" → \"추출\"\n",
      "- \"달아질까요?\" → \"달라질까요?\"\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T12:22:35.075979Z",
     "start_time": "2026-01-10T12:22:34.500244Z"
    }
   },
   "cell_type": "code",
   "source": "%pip -q install --upgrade transformers",
   "id": "6baa515b325d9687",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T12:22:40.004111Z",
     "start_time": "2026-01-10T12:22:36.000458Z"
    }
   },
   "cell_type": "code",
   "source": "from transformers import AutoTokenizer, AutoModelForCausalLM",
   "id": "dc9bad3522d7792e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/pyconda/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T12:23:02.180275Z",
     "start_time": "2026-01-10T12:22:40.932483Z"
    }
   },
   "cell_type": "code",
   "source": [
    "hf_model = \"microsoft/DialoGPT-medium\"\n",
    "max_length = 1000\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(hf_model)\n",
    "model = AutoModelForCausalLM.from_pretrained(hf_model)"
   ],
   "id": "bfbf0514bf225267",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T12:23:04.044662Z",
     "start_time": "2026-01-10T12:23:04.041913Z"
    }
   },
   "cell_type": "code",
   "source": "user_prompt_hf = \"If dinosaurs were alive today, would they possess a threat to people?\"",
   "id": "8ba8738b0660b4eb",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T12:23:05.877936Z",
     "start_time": "2026-01-10T12:23:04.985598Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\n* 참고사항: 위에 표시된 모델 다운로드 경고는 무시하셔도 됩니다.\")\n",
    "user_input_ids = tokenizer.encode(user_prompt_hf + tokenizer.eos_token, return_tensors='pt')\n",
    "response_hf_encoded = model.generate(user_input_ids,\n",
    "                                     max_length=max_length,\n",
    "                                     pad_token_id=tokenizer.eos_token_id)\n",
    "response_hf = tokenizer.decode(response_hf_encoded[:, user_input_ids.shape[-1]:][0], skip_special_tokens=True)\n",
    "print(f\"\\n\\n프롬프트: {user_prompt_hf}\\n\\n{hf_model}의 응답: \\n{response_hf}\")"
   ],
   "id": "a9fbfe894fc60ed7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "* 참고사항: 위에 표시된 모델 다운로드 경고는 무시하셔도 됩니다.\n",
      "\n",
      "\n",
      "프롬프트: If dinosaurs were alive today, would they possess a threat to people?\n",
      "\n",
      "microsoft/DialoGPT-medium의 응답: \n",
      "I think they would be more afraid of the humans.\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T12:23:35.452236Z",
     "start_time": "2026-01-10T12:23:07.249378Z"
    }
   },
   "cell_type": "code",
   "source": [
    "hf_model = \"lcw99/ko-dialoGPT-korean-chit-chat\"\n",
    "max_length = 1000\n",
    "tokenizer = AutoTokenizer.from_pretrained(hf_model)\n",
    "model = AutoModelForCausalLM.from_pretrained(hf_model)\n",
    "user_prompt_hf = \"만약 공룡들이 오늘날 살아있다면, 그들은 인류에게 위협이 될까요?\"\n",
    "print(\"\\n* 참고사항: 위에 표시된 모델 다운로드 경고는 무시하셔도 됩니다.\")\n",
    "user_input_ids = tokenizer.encode(user_prompt_hf + tokenizer.eos_token, return_tensors='pt')\n",
    "response_hf_encoded = model.generate(user_input_ids,\n",
    "                                     max_length=max_length,\n",
    "                                     pad_token_id=tokenizer.eos_token_id)\n",
    "response_hf = tokenizer.decode(response_hf_encoded[:, user_input_ids.shape[-1]:][0], skip_special_tokens=True)\n",
    "print(f\"\\n\\n프롬프트: {user_prompt_hf}\\n\\n{hf_model}의 응답: \\n{response_hf}\")"
   ],
   "id": "3b071f3cd20bfcb8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "* 참고사항: 위에 표시된 모델 다운로드 경고는 무시하셔도 됩니다.\n",
      "\n",
      "\n",
      "프롬프트: 만약 공룡들이 오늘날 살아있다면, 그들은 인류에게 위협이 될까요?\n",
      "\n",
      "lcw99/ko-dialoGPT-korean-chit-chat의 응답: \n",
      "네그럴거같아요. ᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏ\n"
     ]
    }
   ],
   "execution_count": 17
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
